################## ИМПОРТЫ ##################
import os, time, json, psycopg
from contextlib import contextmanager
from typing import Optional, Dict, Any, List, Union
from psycopg.rows import dict_row
from psycopg import sql
from psycopg.errors import OperationalError, UndefinedTable, SyntaxError
from fastapi import HTTPException
from datetime import datetime

PG_DB        = os.getenv("PG_DB", "alldata")
PG_HOST      = os.getenv("PG_HOST", "127.0.0.1")
PG_PORT      = os.getenv("PG_PORT", "5432")
PG_USER      = os.getenv("PG_USER", "postgres")
PG_PASSWORD  = os.getenv("PG_PASSWORD", "1234")

TARGET_DSN = (
    f"dbname={PG_DB} "
    f"user={PG_USER} "
    f"password={PG_PASSWORD} "
    f"host={PG_HOST} "
    f"port={PG_PORT}"
)

ADMIN_DSN = (
    f"dbname=postgres "
    f"user={PG_USER} "
    f"password={PG_PASSWORD} "
    f"host={PG_HOST} "
    f"port={PG_PORT}"
)

#!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Добавить шифрование паролей в бд


################## Подключение к DB ##################
@contextmanager
def get_conn(dsn: str = TARGET_DSN):
    with psycopg.connect(dsn, row_factory=dict_row) as conn:
        yield conn

def init_db():
    ensure_database_exists(PG_DB)
    with _connect_with_retry(TARGET_DSN) as conn:
        with conn.cursor() as cur:
            ddl = """
            CREATE TABLE IF NOT EXISTS users (
                id            BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                name          TEXT NOT NULL,
                surname       TEXT NOT NULL,
                position      TEXT,
                phone         TEXT,
                email         TEXT UNIQUE NOT NULL,          
                company       TEXT,
                address       TEXT,
                notes         TEXT,
                avatar_path   TEXT,
                password      TEXT NOT NULL,                
                created_at    TIMESTAMPTZ NOT NULL DEFAULT now(),
                updated_at    TIMESTAMPTZ NOT NULL DEFAULT now()
            );

            CREATE TABLE IF NOT EXISTS files (
                id           BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                user_id      BIGINT NOT NULL REFERENCES users(id) ON DELETE CASCADE,
                filename     TEXT NOT NULL,
                mime         TEXT,
                size_bytes   BIGINT,
                file_data    BYTEA NOT NULL, 
                created_at   TIMESTAMPTZ NOT NULL DEFAULT now()
            );

            CREATE TABLE IF NOT EXISTS declarations (
                id                BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                user_id           BIGINT NOT NULL REFERENCES users(id) ON DELETE CASCADE,
                title             TEXT NOT NULL,
                goods_description TEXT,
                tnved_code        TEXT,
                attached_file_id  BIGINT REFERENCES files(id) ON DELETE SET NULL,
                meta_json         JSONB,
                created_at        TIMESTAMPTZ NOT NULL DEFAULT now()
            );

            CREATE TABLE IF NOT EXISTS user_profile (
                user_id      BIGINT PRIMARY KEY REFERENCES users(id) ON DELETE CASCADE,
                first_name   TEXT,
                last_name    TEXT,
                position     TEXT,
                phone        TEXT,
                email        TEXT,
                company      TEXT,
                address      TEXT,
                notes        TEXT,
                avatar_path  TEXT,
                created_at   TIMESTAMPTZ NOT NULL DEFAULT now(),
                updated_at   TIMESTAMPTZ NOT NULL DEFAULT now()
            );
            CREATE TABLE IF NOT EXISTS declaration_files (
                id              BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                declaration_id  BIGINT NOT NULL REFERENCES declarations(id) ON DELETE CASCADE,
                file_id         BIGINT NOT NULL REFERENCES files(id) ON DELETE CASCADE,
                doc_key         TEXT NOT NULL,  -- 'invoice', 'packing', 'contract', ...
                created_at      TIMESTAMPTZ NOT NULL DEFAULT now()
            );
            CREATE TABLE IF NOT EXISTS jobs (
                id          BIGSERIAL PRIMARY KEY,
                status      TEXT NOT NULL DEFAULT 'queued',  -- queued | processing | done | error
                decl_id     BIGINT NOT NULL,
                file_id     BIGINT NOT NULL,
                doc_key     TEXT NOT NULL,
                attempts    INT NOT NULL DEFAULT 0,
                error_text  TEXT,
                result_json JSONB,
                created_at  TIMESTAMPTZ NOT NULL DEFAULT now(),
                started_at  TIMESTAMPTZ,
                finished_at TIMESTAMPTZ
            );

            -- функция обновления updated_at
            CREATE OR REPLACE FUNCTION set_updated_at()
            RETURNS trigger AS $$
            BEGIN
                NEW.updated_at := now();
                RETURN NEW;
            END;
            $$ LANGUAGE plpgsql;

            DO $$
            BEGIN
                IF NOT EXISTS (
                    SELECT 1 FROM pg_trigger WHERE tgname = 'trg_users_updated_at'
                ) THEN
                    CREATE TRIGGER trg_users_updated_at
                    BEFORE UPDATE ON users
                    FOR EACH ROW EXECUTE FUNCTION set_updated_at();
                END IF;

                IF NOT EXISTS (
                    SELECT 1 FROM pg_trigger WHERE tgname = 'trg_user_profile_updated_at'
                ) THEN
                    CREATE TRIGGER trg_user_profile_updated_at
                    BEFORE UPDATE ON user_profile
                    FOR EACH ROW EXECUTE FUNCTION set_updated_at();
                END IF;
            END$$;

            CREATE INDEX IF NOT EXISTS idx_files_user_id         ON files(user_id);
            CREATE INDEX IF NOT EXISTS idx_declarations_user_id  ON declarations(user_id);
            CREATE INDEX IF NOT EXISTS idx_declarations_file_id  ON declarations(attached_file_id);
            CREATE INDEX IF NOT EXISTS idx_users_email           ON users(email);
            CREATE INDEX IF NOT EXISTS idx_decl_files_decl_id ON declaration_files(declaration_id);
            CREATE INDEX IF NOT EXISTS idx_decl_files_file_id ON declaration_files(file_id);
            """
            with get_conn(TARGET_DSN) as conn:
                with conn.cursor() as cur:
                    cur.execute(ddl)
                conn.commit()

def ensure_database_exists(dbname: str = PG_DB):
    """Создаёт БД, если её ещё нет. CREATE DATABASE выполняем вне транзакции."""
    with psycopg.connect(ADMIN_DSN) as conn:
        conn.autocommit = True  # важно для CREATE DATABASE
        with conn.cursor() as cur:
            cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (dbname,))
            if not cur.fetchone():
                cur.execute(sql.SQL("CREATE DATABASE {}").format(sql.Identifier(dbname)))

def _connect_with_retry(dsn: str, retries: int = 5, delay_sec: float = 0.2):
    last_ex = None
    for _ in range(retries):
        try:
            return psycopg.connect(dsn, row_factory=dict_row)
        except OperationalError as ex:
            last_ex = ex
            time.sleep(delay_sec)
    raise last_ex

################## Пользователи ##################
def get_user_by_email(email: str) -> Optional[Dict[str, Any]]:
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute("SELECT * FROM users WHERE email = %s", (email,))
        row = cur.fetchone()
        return dict(row) if row else None

def get_user_by_id(user_id: int) -> Optional[Dict[str, Any]]:
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute("SELECT * FROM users WHERE id = %s", (user_id,))
        row = cur.fetchone()
        return dict(row) if row else None

def update_user(user_id: int, **fields):
    allowed = {"name","surname","position","phone","email","company","address","notes","avatar_path","password"}
    sets, vals = [], []
    for k, v in fields.items():
        if k in allowed:
            sets.append(f"{k} = %s")
            vals.append(v)
    if not sets:
        return
    # updated_at обновится триггером, но можно задублировать — не нужно
    vals.append(user_id)
    q = f"UPDATE users SET {', '.join(sets)} WHERE id = %s"
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, tuple(vals))
        conn.commit()

def create_user(
    name: str,
    surname: str,
    email: str,
    password: str,
    position: Optional[str] = None,
    phone: Optional[str] = None,
    company: Optional[str] = None,
    address: Optional[str] = None,
    notes: Optional[str] = None,
    avatar_path: Optional[str] = None
) -> int:
    q = """
    INSERT INTO users (name, surname, position, phone, email, company, address, notes, avatar_path, password)
    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
    RETURNING id
    """
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (name, surname, position, phone, email, company, address, notes, avatar_path, password))
        new_id = cur.fetchone()["id"]
        conn.commit()
        return int(new_id)

################## Файлы ##################
def add_file(user_id: int, filename: str, mime: str, file_bytes: bytes) -> int:
    q = """
    INSERT INTO files(user_id, filename, mime, size_bytes, file_data)
    VALUES (%s, %s, %s, %s, %s)
    RETURNING id
    """
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (user_id, filename, mime, len(file_bytes), psycopg.Binary(file_bytes)))
        file_id = cur.fetchone()["id"]
        conn.commit()
        return int(file_id)
        
def list_files(user_id: int, limit: int = 200) -> List[Dict[str, Any]]:
    q = """
    SELECT id, filename, mime, size_bytes, created_at
    FROM files
    WHERE user_id = %s
    ORDER BY created_at DESC
    LIMIT %s
    """
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (user_id, limit))
        return [dict(r) for r in cur.fetchall()]

def get_file(file_id: int) -> Optional[Dict[str, Any]]:
    """
    Возвращает один файл по id вместе с бинарными данными (file_data).
    Используй для download_button.
    """
    q = """
    SELECT id, user_id, filename, mime, size_bytes, file_data, created_at
    FROM files
    WHERE id = %s
    """
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (file_id,))
        row = cur.fetchone()
        return dict(row) if row else None

def search_files(user_id: int, query: str, limit: int = 500) -> List[Dict[str, Any]]:
    qsql = """
    SELECT id, filename, mime, size_bytes, created_at
    FROM files
    WHERE user_id = %s
      AND (filename ILIKE %s OR COALESCE(mime,'') ILIKE %s)
    ORDER BY created_at DESC
    LIMIT %s
    """
    like = f"%{query}%"
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(qsql, (user_id, like, like, limit))
        return [dict(r) for r in cur.fetchall()]

def delete_file(file_id: int) -> int:
    """Удаляет сам файл. Возвращает 1 если удалён, 0 если нет."""
    q = "DELETE FROM files WHERE id=%s"
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (file_id,))
        affected = cur.rowcount
        conn.commit()
        return affected

def count_file_links(file_id: int) -> int:
    q = "SELECT COUNT(*) AS c FROM declaration_files WHERE file_id=%s"
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (file_id,))
        row = cur.fetchone()
        return int(row["c"])

def replace_file(declaration_id: int, user_id: int, doc_key: str,
                      filename: str, mime: str, data: bytes) -> int:
    """
    Полная замена файла для (declaration_id, doc_key):
      1) Находим все файлы, привязанные к декларации под этим doc_key.
      2) Удаляем их из files (связи в declaration_files удалятся каскадно).
      3) Вставляем новый файл и создаём новую связь.
      4) Возвращаем id нового файла.
    Все действия — в одной транзакции.
    """
    q_select_old = """
        SELECT f.id
        FROM declaration_files df
        JOIN files f ON f.id = df.file_id
        WHERE df.declaration_id = %s AND df.doc_key = %s
    """
    q_delete_old = "DELETE FROM files WHERE id = ANY(%s)"
    q_insert_file = """
        INSERT INTO files (user_id, filename, mime, size_bytes, file_data)
        VALUES (%s, %s, %s, %s, %s)
        RETURNING id
    """
    q_link = """
        INSERT INTO declaration_files (declaration_id, file_id, doc_key)
        VALUES (%s, %s, %s)
    """

    with get_conn() as conn, conn.cursor() as cur:
        # 1) старые file_id
        cur.execute(q_select_old, (declaration_id, doc_key))
        old_ids = [r["id"] for r in cur.fetchall()]

        # 2) удаляем старые файлы (каскадно уберёт ссылки)
        if old_ids:
            cur.execute(q_delete_old, (old_ids,))

        # 3) создаём новый файл
        cur.execute(
            q_insert_file,
            (user_id, filename, mime, len(data), psycopg.Binary(data))
        )
        new_fid = int(cur.fetchone()["id"])

        # 4) новая привязка
        cur.execute(q_link, (declaration_id, new_fid, doc_key))
        conn.commit()
        return new_fid
################## Декларации ##################
def add_declaration(
    user_id: int,
    title: str,
    created_at: Optional[datetime] = None,
    goods_description: Optional[str] = None,
    tnved_code: Optional[str] = None,
    attached_file_id: Optional[int] = None,
    meta_json: Optional[Union[str, dict]] = None
) -> int:
    """
    Если created_at не передан — используется DEFAULT now() на уровне БД.
    meta_json можно передавать dict — мы сами сделаем json.dumps.
    """
    if isinstance(meta_json, dict):
        meta_json = json.dumps(meta_json, ensure_ascii=False)

    q = """
    INSERT INTO declarations(
        user_id, title, goods_description, tnved_code, attached_file_id, meta_json, created_at
    )
    VALUES (%s, %s, %s, %s, %s, %s::jsonb, COALESCE(%s::timestamptz, now()))
    RETURNING id
    """
    # В PostgreSQL COALESCE(%s::timestamptz, DEFAULT) подставит DEFAULT now(), если param NULL.
    # Альтернатива: VALUES (..., COALESCE(%s::timestamptz, NOW()))
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(
            q,
            (user_id, title, goods_description, tnved_code, attached_file_id, meta_json, created_at)
        )
        dec_id = cur.fetchone()["id"]
        conn.commit()
        return int(dec_id)

def list_declarations(user_id: int, limit: int = 200) -> List[Dict[str, Any]]:
    q = """
    SELECT d.id, d.title, d.goods_description, d.tnved_code,
           d.attached_file_id, d.created_at, f.filename AS file_name
    FROM declarations d
    LEFT JOIN files f ON f.id = d.attached_file_id
    WHERE d.user_id = %s
    ORDER BY d.created_at DESC
    LIMIT %s
    """
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (user_id, limit))
        return [dict(r) for r in cur.fetchall()]

def update_declaration(decl_id: int, **fields) -> None:
    """
    Обновить поля декларации (например, meta_json, title, tnved_code...).
    Передавать только те поля, которые реально нужны.
    """
    allowed = {"title", "goods_description", "tnved_code", "attached_file_id", "meta_json"}
    sets, vals = [], []
    for k, v in fields.items():
        if k in allowed:
            if k == "meta_json" and isinstance(v, dict):
                sets.append(f"{k} = %s::jsonb")
                vals.append(json.dumps(v, ensure_ascii=False))
            else:
                sets.append(f"{k} = %s")
                vals.append(v)

    if not sets:
        return  # ничего не обновляем

    vals.append(decl_id)
    q = f"UPDATE declarations SET {', '.join(sets)} WHERE id = %s"

    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, tuple(vals))
        conn.commit()

def get_declaration_date(declaration_id: int) -> Optional[str]:
    """
    Возвращает строку с датой создания декларации в формате DD.MM.YYYY,
    либо None если запись не найдена.
    """
    q = "SELECT to_char(created_at, 'DD.MM.YYYY') AS created_date FROM declarations WHERE id = %s"
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (declaration_id,))
        row = cur.fetchone()
        return (row or {}).get("created_date")
    
def get_declaration_datetime(declaration_id: int) -> str:
    q = """
        SELECT to_char(created_at, 'YYYY-MM-DD"T"HH24:MI:SS') AS created_date FROM declarations WHERE id = %s
    """
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (declaration_id,))
        row = cur.fetchone()
        return (row or {}).get("created_date")

    
################## Профиль пользователя ##################
def get_user_profile(user_id: int) -> Optional[Dict[str, Any]]:
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute("SELECT * FROM user_profile WHERE user_id = %s", (user_id,))
        row = cur.fetchone()
        return dict(row) if row else None

def upsert_user_profile(user_id: int, data: Dict[str, Any]) -> None:
    keys = ["first_name","last_name","position","phone","email","company","address","notes","avatar_path"]
    cols = ", ".join(keys)
    placeholders = ", ".join(["%s"] * len(keys))
    vals = [data.get(k) for k in keys]

    q = f"""
    INSERT INTO user_profile (user_id, {cols})
    VALUES (%s, {placeholders})
    ON CONFLICT (user_id)
    DO UPDATE SET
        {", ".join([f"{k} = EXCLUDED.{k}" for k in keys])},
        updated_at = now()
    """
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (user_id, *vals))
        conn.commit()

################## Файлы декларации ##################
def link_file_to_declaration(declaration_id: int, file_id: int, doc_key: str, replace: bool = False) -> int:
    """
    Привязать файл к декларации под ключом doc_key.
    Если replace=True — сначала удаляет все существующие привязки с тем же (declaration_id, doc_key),
    затем создаёт новую (гарантирует единственную актуальную запись).
    Возвращает id записи в declaration_files.
    """
    q_insert = """
        INSERT INTO declaration_files (declaration_id, file_id, doc_key)
        VALUES (%s, %s, %s)
        RETURNING id
    """
    q_delete = """
        DELETE FROM declaration_files
        WHERE declaration_id = %s AND doc_key = %s
    """

    with get_conn() as conn, conn.cursor() as cur:
        if replace:
            cur.execute(q_delete, (declaration_id, doc_key))

        cur.execute(q_insert, (declaration_id, file_id, doc_key))
        link_id = cur.fetchone()["id"]
        conn.commit()
        return int(link_id)

def list_declaration_files(declaration_id: int) -> List[Dict[str, Any]]:
    q = """
    SELECT df.id as link_id, df.doc_key, df.created_at,
           f.id as file_id, f.filename, f.mime, f.size_bytes
    FROM declaration_files df
    JOIN files f ON f.id = df.file_id
    WHERE df.declaration_id = %s
    ORDER BY df.created_at DESC
    """
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (declaration_id,))
        return [dict(r) for r in cur.fetchall()]

def unlink_file_from_declaration(declaration_id: int, file_id: int) -> int:
    """Удалить связь файла с декларацией. Возвращает кол-во удалённых строк (0 или 1+ если дубликаты)."""
    q = "DELETE FROM declaration_files WHERE declaration_id=%s AND file_id=%s RETURNING id"
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (declaration_id, file_id))
        deleted = cur.rowcount
        conn.commit()
        return deleted

################## Очередь файлов ##################
def jobs_create(decl_id: int, file_id: int, doc_key: str) -> int:
    q = """INSERT INTO jobs(decl_id, file_id, doc_key, status)
           VALUES (%s,%s,%s,'queued') RETURNING id"""
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (decl_id, file_id, doc_key))
        jid = cur.fetchone()["id"]
        conn.commit()
        return int(jid)

def jobs_get(job_id: int) -> Optional[Dict[str, Any]]:
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute("SELECT * FROM jobs WHERE id=%s", (job_id,))
        row = cur.fetchone()
        return dict(row) if row else None

def jobs_list_by_decl(decl_id: int, limit: int = 200) -> List[Dict[str, Any]]:
    q = """SELECT * FROM jobs WHERE decl_id=%s ORDER BY created_at DESC LIMIT %s"""
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (decl_id, limit))
        return [dict(r) for r in cur.fetchall()]

def jobs_claim_next() -> Optional[Dict[str, Any]]:
    # атомарно берём следующую queued-задачу (Postgres)
    with psycopg.connect(TARGET_DSN, row_factory=dict_row) as c:
        c.autocommit = False
        with c.cursor() as cur:
            row = cur.execute("""
                SELECT * FROM jobs
                WHERE status='queued'
                ORDER BY created_at ASC
                FOR UPDATE SKIP LOCKED
                LIMIT 1
            """).fetchone()
            if not row:
                c.rollback()
                return None
            cur.execute("""
                UPDATE jobs
                   SET status='processing', started_at=now(), attempts=attempts+1
                 WHERE id=%s
            """, (row["id"],))
            c.commit()
            return dict(row)

def jobs_finish_ok(job_id: int, result: Dict[str, Any]) -> None:
    q = """UPDATE jobs SET status='done', result_json=%s, finished_at=now() WHERE id=%s"""
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (json.dumps(result, ensure_ascii=False), job_id))
        conn.commit()

def jobs_finish_err(job_id: int, err: str) -> None:
    q = """UPDATE jobs SET status='error', error_text=%s, finished_at=now() WHERE id=%s"""
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (err[:4000], job_id))
        conn.commit()


################## Изменения в alldata ##################
def get_overrides(decl_id: int) -> Dict[str, Any]:
    q = "SELECT meta_json FROM declarations WHERE id=%s"
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (decl_id,))
        row = cur.fetchone()
        meta = (row or {}).get("meta_json") or {}
        if isinstance(meta, str):
            try:
                meta = json.loads(meta)
            except Exception:
                meta = {}
        return meta.get("overrides", {})

def save_overrides(decl_id: int, overrides: Dict[str, Any]) -> None:
    # запишем overrides внутрь meta_json.overrides
    q = """
    UPDATE declarations
       SET meta_json = COALESCE(meta_json, '{}'::jsonb)
                       || jsonb_build_object('overrides', %s::jsonb)
     WHERE id = %s
    """
    with get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (json.dumps(overrides, ensure_ascii=False), decl_id))
        conn.commit()



